{"templates":[{"id":"AuditLogAppendingFailure","origin":"com.palantir.sls.logging:sls-logging-log4j:10.10.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"logging.appender.failure.count","tags":{"type":[{"type":"string","string":"audit"},{"type":"string","string":"audit.3"}]},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId","type"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}},"p0-all-hours":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"FIVE_MINUTES","thresholdFrequency":{"type":"wholeWindow","wholeWindow":{}}}}},"message":"There has been a failure writing {{aggregations.type}} logs.\n\nFor the exact error, look for ERROR logs from origin `com.palantir.sls.logging.log4j.SlsStatusConsoleListener` to view error logs for the `StatusLogger`.\nIf the service is deployed on-prem, `StatusLogger` logs will be present on disk in the `startup.log` file and will not be available in Grafana.\nIn particular, the ERROR log with message starting with \"Failure appending log\" may be useful.\n\nThis error may also be caused by service producing too many logs or too large logs. Use the sls-logging dashboard to investigate the number and size of logs being produced by your service.\n\nIf needed, loop in pd-dev-infrastructure-runtime for additional help debugging, or dev-infrastructure-audit for help debugging audit-specific issues.\n\n\uD83D\uDCCA sls-logging: https://grafana.palantircloud.com/grafana/d/b44c799f-dffd-4c7a-bd70-129df821e578/sls-logging","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"LogAppendingFailure","origin":"com.palantir.sls.logging:sls-logging-log4j:10.10.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"logging.appender.failure.count","tags":{},"tagExclusions":{"type":[{"type":"string","string":"audit"},{"type":"string","string":"audit.3"}]},"aggregations":["apolloenvironmentid","host","nodeId","type"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}},"p1-escalating":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"FIVE_MINUTES","thresholdFrequency":{"type":"wholeWindow","wholeWindow":{}}}}},"message":"There has been a failure writing {{aggregations.type}} logs.\n\nFor the exact error, look for ERROR logs from origin `com.palantir.sls.logging.log4j.SlsStatusConsoleListener` to view error logs for the `StatusLogger`.\nIf the service is deployed on-prem, `StatusLogger` logs will be present on disk in the `startup.log` file and will not be available in Grafana.\nIn particular, the ERROR log with message starting with \"Failure appending log\" may be useful.\n\nThis error may also be caused by service producing too many logs or too large logs. Use the sls-logging dashboard to investigate the number and size of logs being produced by your service.\n\nIf needed, loop in pd-dev-infrastructure-runtime for additional help debugging, or dev-infrastructure-audit for help debugging audit-specific issues.\n\n\uD83D\uDCCA sls-logging: https://grafana.palantircloud.com/grafana/d/b44c799f-dffd-4c7a-bd70-129df821e578/sls-logging","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"SynchronousLogging","origin":"com.palantir.sls.logging:sls-logging-log4j:10.10.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"logging.queue.full.count","tags":{"route":[{"type":"string","string":"synchronous"}]},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId"]},"events":{"events":{"tracking":{"comparator":"GREATER_THAN","value":{"type":"double","double":100000.0}}}},"window":"FIVE_MINUTES","thresholdFrequency":{"type":"atAllTimes","atAllTimes":{"window":{"amount":100,"unit":"SECONDS"}}}}}},"message":"Performance is degraded due to synchronous logging with the asynchronous logging queue is full. This\nmay be expected if you are actively running experiments with DEBUG or TRACE level logging enabled, otherwise you\nmay need to investigate the source of increased logging load, and reduce logging in hot paths.\nApplication code is blocking on logging statements, increasing application latency.\nPlease investigate using the linked dashboard, and determine the largest source of logging. If events are\ndominated by service logging at `TRACE` or `DEBUG` level, there is most likely an old configuration override\non the impacted stack which must be removed. Otherwise, it is possible that application code is logging more\naggressively than expected.\n\uD83D\uDCCA sls-logging: https://grafana.palantircloud.com/grafana/d/b44c799f-dffd-4c7a-bd70-129df821e578/sls-logging","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"CredentialLogging","origin":"com.palantir.sls.logging:sls-logging-monitors:10.10.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"logging.sls.redaction.count","tags":{"provided":[{"type":"string","string":"do-not-log"}]},"tagExclusions":{},"aggregations":["type","allowed","provided"]},"events":{"events":{"product-defect":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"TEN_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"An auth token has been logged. The logging framework has automatically redacted the value before recording\nlog data, replacing the offending object with \"===REDACTED===\", however this is a serious problem and represents\na failure to correctly classify data for logging. Credentials, tokens, private keys, and auth tokens are never\nacceptable to log in any form, even as unsafe.","aggregationScheme":null},{"id":"UnsafeLogging","origin":"com.palantir.sls.logging:sls-logging-monitors:10.10.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"logging.sls.redaction.count","tags":{},"tagExclusions":{"provided":[{"type":"string","string":"do-not-log"}]},"aggregations":["type","allowed","provided"]},"events":{"events":{"product-defect":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"TEN_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Unsafe types have been logged as safe. The logging framework has automatically redacted the value before\nrecording log data, replacing the offending object with \"===REDACTED===\", however this is a serious problem and\nrepresents a failure to correctly classify data for logging which may not be handled by sls-logging in all cases.","aggregationScheme":null},{"id":"ServiceStwGc","origin":"com.palantir.witchcraft:witchcraft-service-stw-gc:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"jvm.safepoint.time.value","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":180000.0}},"heaphisto-diagnostic-no-ticket":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":300000.0}},"jfr-diagnostic-tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":120000.0}},"p0-business-hours":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":300000.0}}}},"window":"TEN_MINUTES","thresholdFrequency":{"type":"wholeWindow","wholeWindow":{}}}}},"message":"\uD83D\uDEA8 ‚è∞ Service is spending at least 20% of its time in STW GC which directly impacts its ability to respond to requests.\nIf service spends at least 30% of its time in STW GC, then adjudication will fail to let services roll back during b/g as there is degraded memory behavior.\nIf service spends at least 50% of its time in STW GC, then it is a business-hours P0 alert as this means the node is unhealthy. This indicates there\nis either a memory leak or the JVM needs more memory to operate efficiently.\n\uD83D\uDD0D Investigate why the service is having high STW GC using diagnostic tools (datadog dashboards, JFRs, heap histograms, aries logs).\n\uD83D\uDCCA Dashboards:\n* Baseline aggregated host dashboard: https://grafana.palantircloud.com/grafana/d/e0b2aa02-ee58-4468-ad3e-5f7b829fba9f/b6066bbe-115d-5eca-851c-e0802ac82523?orgId=1&refresh=1m&var-interval=$__auto_interval_interval&var-host={{aggregations.host}}&var-pt_function=All&var-apolloenvironmentid={{aggregations.apolloenvironmentid}}&var-mountpoint=All\n* Precogs garbage collection dashboard: https://grafana.palantircloud.com/grafana/d/d95dce14-08b6-499e-a7c3-243ef4caccfd/precogs-garbage-collection-do-not-edit?orgId=1&var-interval=$__auto_interval_interval&var-apolloenvironmentid={{aggregations.apolloenvironmentid}}&var-service=All&var-environment=All&var-stack=All&var-host={{aggregations.host}}\n* Witchcraft service metrics dashboard: https://grafana.palantircloud.com/grafana/d/aa30872f-89fc-4ccf-9d21-bdb237e33309/witchcraft-improved?orgId=1&var-nodeid={{aggregations.nodeId}}","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"BlockedIoThread","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.worker.io-thread.latency.max","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":5000000.0}},"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":3000000.0}},"jfr-diagnostic-tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":5000000.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atAllTimes","atAllTimes":{}}}}},"message":"Service is taking an exceedingly long time to execute work on non-blocking I/O threads. This will induce\nconnection and request latency, potentially triggering a feedback loop into a prolonged outage depending on the cause.\nIt\\'s important to determine the cause: This maybe the result of elevated jvm pauses and not specific to I/O\nthreads. If Safepoint or hiccup time is elevated, this is likely a more general problem. See `jvm.safepoint.time`\nand `jvm.threads.hiccup.max` in the Witchcraft dashboard to make this determination.\nOtherwise, please reach out to #dev-witchcraft-java for assistance in determining the root cause.\n\uD83D\uDCCA Witchcraft: https://grafana.palantircloud.com/grafana/d/aa30872f-89fc-4ccf-9d21-bdb237e33309","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"BlockedThreads","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"directRatio","directRatio":{"numerators":[{"metric":"jvm.threads.blocked.count.value","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","deployment","host","nodeId","service","product"]}],"denominators":[{"metric":"jvm.threads.count.value","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","deployment","host","nodeId","service","product"]}],"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":0.5}},"jfr-diagnostic-tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":0.5}},"product-defect":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":0.9}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Service has a significant proportion of threads in BLOCKED state,\nlikely the result of a deadlock or significant resource contention.\n\uD83D\uDCCA Witchcraft: https://grafana.palantircloud.com/grafana/d/aa30872f-89fc-4ccf-9d21-bdb237e33309","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"CacheStatsDisabled","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"cache.stats.disabled.count","tags":{},"tagExclusions":{},"aggregations":["cache"]},"events":{"events":{"product-defect":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"ONE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Metrics on a Caffeine cache are unavailable due to a programming error.\n\nProduct teams should write a PR to use the pattern described here:\n- https://github.com/palantir/tritium#instrumenting-a-caffeine-cache\n\nSee example PR here:\n- https://github.palantir.build/foundry/usage-aggregator/pull/7620","aggregationScheme":null},{"id":"ClassLeak","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"jvm.classloader.loaded.current.value","tags":{},"tagExclusions":{},"aggregations":[]},"events":{"events":{"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN","value":{"type":"double","double":100000.0}},"product-defect":{"comparator":"GREATER_THAN","value":{"type":"double","double":120000.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Service has far more loaded classes than expected, this is likely the result\nof a class loading leak that will crash the JVM due to metaspace OOMs.","aggregationScheme":null},{"id":"ClientUsingInsecureCiphers","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.connection.insecure.cipher.count","tags":{},"tagExclusions":{},"aggregations":["sourcepackage","cipher"]},"events":{"events":{"delegate-tracking-to-package":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"ONE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Detected requests using insecure ciphers which will be removed from Witchcraft. These requests\nwill fail once ciphers are updated, and most likely are the result of misconfigured or out-of-date clients.\nYou can determine the source of these requests by checking the WARN logging from origin\n`com.palantir.witchcraft.ConnectionDiagnosticsHandler`.","aggregationScheme":null},{"id":"ClientsSendingRequestsWithoutEncodingIllegalCharacters","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.request.unescaped.character.count","tags":{},"tagExclusions":{},"aggregations":[]},"events":{"events":{"no-op":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"ONE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Detected requests using illegal unescaped characters in the request line.\nThese requests will fail once Witchcraft begins to validate against illegal characters.","aggregationScheme":null},{"id":"DangerousFeignStreamBuffering","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"feign.client.dangerous.buffering.count","tags":{},"tagExclusions":{},"aggregations":["client","direction"]},"events":{"events":{"no-op":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"TEN_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Feign clients should never be used to send or receive binary streams because they fully buffer\nthe data on heap which is likely to OOM and puts substantial pressure on the garbage collector,\nincreasing utilization across the entire JVM. Dialogue clients are preferred as they do not cause\nsuch heap churn, and allow streaming beyond two gigabytes of data.","aggregationScheme":null},{"id":"DiagnosticHyperionEte","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"diagnostics.diagnostic-hyperion-ete.value","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","deployment","host","nodeId","service","product"]},"events":{"events":{"jfr-diagnostic-no-ticket":{"comparator":"LESS_THAN","value":{"type":"double","double":300000.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"A monitor used to collect a JFR diagnostic (or other sls-debug diagnostic) from this\nWitchcraft server only via manually triggering the `diagnostic.hyperion.ete.v1` diagnostic type.\nThis is intended to debug the end-to-end pipeline for collecting sls-debug diagnostics via hyperion\nmonitors, rather than via the diagnostic endpoint itself.","aggregationScheme":null},{"id":"DialogueExcessiveLeasedConnections","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"dialogue.client.pool.size.value","tags":{"state":[{"type":"string","string":"leased"}]},"tagExclusions":{},"aggregations":["client-name","deployment","product"]},"events":{"events":{"tracking":{"comparator":"GREATER_THAN","value":{"type":"double","double":500.0}}}},"window":"TEN_MINUTES","frequency":{"type":"atAllTimes","atAllTimes":{}}}}},"message":"The Dialogue connection pool is showing a very high number of leased connections.\nThis is unexpected, and may be the result of a resource leak, or an overloaded server.\nThis will lead to retained heap growth and file descriptor exhaustion if allowed to grow unchecked.\n\uD83D\uDCCA Dialogue dashboard: https://palantir.datadoghq.com/dashboard/hss-mmd-3xx/infra-dialogue?tpl_var_deployment={{aggregations.deployment}}&tpl_var_clientName={{aggregations.client-name}}&tpl_var_channelName={{aggregations.client-name}}&tpl_var_product={{aggregations.product}}\nPlease reach out to the Software Infrastructure team for guidance.","aggregationScheme":null},{"id":"DialogueResponseLeak","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"dialogue.client.response.leak.count","tags":{},"tagExclusions":{},"aggregations":["client-name","service-name","endpoint","deployment"]},"events":{"events":{"tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}}}},"window":"ONE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Dialogue responses and response InputStreams must always be closed. Failure to do so\nresults in system resource leaks, degraded performance, and eventually crashes. In most cases\nleaks are the result of improperly handled binary response data.\nMore precise information can be collected including stack traces from the construction-point\nof leaked requests by enabling TRACE level logging on \"com.palantir.dialogue.hc5.ResponseLeakDetector\"\n\uD83D\uDCCA Dialogue dashboard: https://grafana.palantircloud.com/grafana/d/b0f12850-c81b-4b61-a323-fa8a0e04a855/infra-dialogue?var-interval=$__auto&orgId=1&from=now-30m&to=now&var-deployment={{aggregations.deployment}}&var-env=$__all&var-channelname=$__all&var-clientname={{aggregations.client-name}}&var-host=$__all&var-service={{aggregations.service-name}}&var-endpoint={{aggregations.endpoint}}&var-response_status=$__all\nFeel free to reach out to the Software Infrastructure team for guidance.","aggregationScheme":null},{"id":"FileDescriptorExhaustion","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"jvm.filedescriptor.value","tags":{},"tagExclusions":{},"aggregations":["host","nodeId"]},"events":{"events":{"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.8}},"p0-business-hours":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.9}}}},"window":"FIVE_MINUTES","frequency":{"type":"atAllTimes","atAllTimes":{}}}}},"message":"This Witchcraft server is using more than 90% of its maximum allowed file descriptors. If this\nreaches 100%, the server will no longer be able to open files (including sockets).","aggregationScheme":null},{"id":"HighLiveDataUsage","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"directRatio","directRatio":{"numerators":[{"metric":"jvm.heap.size","tags":{"collection":[{"type":"string","string":"g1-old-gen"},{"type":"string","string":"shenandoah"},{"type":"string","string":"zgc-old-generation"}],"when":[{"type":"string","string":"after"}],"collector":[{"type":"string","string":"zgc_major_cycles"},{"type":"string","string":"g1_old_generation"},{"type":"string","string":"shenandoah_cycles"}]},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]}],"denominators":[{"metric":"jvm.memory.heap.max.value","tags":{},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]}],"events":{"events":{"heaphisto-diagnostic-no-ticket":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":0.9}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Service is using over 90% of the heap for live (non-garbage) data after a full GC event. The service likely does not have enough free heap to ensure healthy GC performance.\nA heap histogram has been triggered by this monitor. Check the Apollo monitor tab to download the histogram to see what objects are using the most heap space.","aggregationScheme":null},{"id":"Hprof","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"jvm.hprof.value","tags":{},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]},"events":{"events":{"tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}}}},"window":"FIVE_MINUTES","thresholdFrequency":{"type":"atLeastOnce","atLeastOnce":{"window":{"amount":5,"unit":"MINUTES"}}}}}},"message":"Hprof file detected. Remove Hprof from service directory and investigate.","aggregationScheme":null},{"id":"InvalidUri","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"client.uri.invalid.count","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId","channel-name"]},"events":{"events":{"tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}}}},"window":"FIVE_MINUTES","thresholdFrequency":{"type":"atLeastOnce","atLeastOnce":{"window":{"amount":5,"unit":"MINUTES"}}}}}},"message":"Invalid URIs detected, clients may not work as expected. Please inspect logging for origin `com.palantir.dialogue.clients.DnsSupport` to find the root cause.","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"JfrRecorderInitializationFailed","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"diagnostics.jfr-recorder-initialization-failed.count","tags":{},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]},"events":{"events":{"tracking":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"The service JFR Recorder failed to be initialized. Check the service logs for origin\n`com.palantir.witchcraft.Witchcraft` with message `Failed to create a JfrRecorder. The JFR diagnostic will fail`.","aggregationScheme":null},{"id":"JvmCrash","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"changeOfMeter","changeOfMeter":{"series":{"metric":"jvm.hs-err-pid.value","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","deployment","host","nodeId","service","product"]},"events":{"events":{"java-crash-log-diagnostic":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}},"previous-run-jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}},"tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}}}},"window":"FIVE_MINUTES","thresholdFrequency":{"type":"atLeastOnce","atLeastOnce":{"window":{"amount":5,"unit":"MINUTES"}}}}}},"message":"The service\\'s JVM has crashed (due to segfaults and/or OOMs). Determine why the service is crashing,\nusually involves OOMs (look at GC/heap graphs and the hs_err_pid file on the host of the JVM that crashed).\nThe hs_err_pid file is also available in Autopilot as a diagnostic command.\nThe ContainerTerminatedError monitor may also have fired.","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"NativeMemoryTrackingFailure","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"jvm.native.memory.tracking.numConsecutiveFailures.value","tags":{},"tagExclusions":{},"aggregations":["sourcepackage"]},"events":{"events":{"delegate-tracking-to-package":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":2.0}}}},"window":"ONE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"There was a failure invoking jcmd to collect native memory metrics. This is usually caused by a deleted\n/tmp/.java_pid<pid> file for your server and causes the JVM to output thread dumps to stdout (see more information\nabout Dynamic Attach Mechanism in the JVM: http://openjdk.java.net/groups/hotspot/docs/Serviceability.html#battach).\nThis monitor alerts to help debug the cause of these deletions, as part of an ongoing investigation:\nif you receive this alert, please notify https://support-jira.palantir.tech/browse/PDS-209940.","aggregationScheme":null},{"id":"PerSourceConnectionUtilization","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.connection.per-source.utilization-max.value","tags":{},"tagExclusions":{},"aggregations":["host","nodeId","listener"]},"events":{"events":{"information":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.5}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"This Witchcraft server has a single client nearing the per-source connection limit.\nWhen this limit is reached, the client will not be able to create new connections until existing\nconnections have been closed.\nPer-source connection limits represent a very large portion of the Witchcraft server total connection limit,\nfar larger than the worker threadpool size, so it\\'s likely the offending client is misconfigured in a way that\nfails to effectively reuse connections.\nDiagnosis can be challenging, you should enable DEBUG logging on the\n`com.palantir.witchcraft.ConnectionDiagnosticsHandler` origin, which logs user-agent information for each\nnew connection after it completes its first request.","aggregationScheme":null},{"id":"ServerConnectionUtilization","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.connection.utilization-max.value","tags":{},"tagExclusions":{},"aggregations":["host","nodeId","listener"]},"events":{"events":{"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.8}},"p0-business-hours":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.9}}}},"window":"FIVE_MINUTES","frequency":{"type":"atAllTimes","atAllTimes":{}}}}},"message":"This Witchcraft server is using more than 90% of its maximum allowed connections, either some external\nclient is holding too many connections open, or the server itself is leaking connections. If this continues,\nthe server will no longer be able to accept incoming connections.\nIf this is expected, you may either increase the maximum value directly in the\n\"install.server.max-connections\" (default is 10 max-threads) or increase\n\"install.server.max-threads\" (default is max(256, 32 * processors)), or allocate more processors to increase\nthese values without modifying configuration.","aggregationScheme":null},{"id":"ThreadLeak","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"directRatio","directRatio":{"numerators":[{"metric":"jvm.threads.count.value","tags":{},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]}],"denominators":[{"metric":"jvm.processors.value","tags":{},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]}],"events":{"events":{"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN","value":{"type":"double","double":1000.0}},"jfr-diagnostic-tracking":{"comparator":"GREATER_THAN","value":{"type":"double","double":2000.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Service has more than 1000 active threads per allocated processor,\nas this is likely the result of a thread leak that will crash the JVM due\nto native OutOfMemoryError or container OOMKill.","aggregationScheme":null},{"id":"ThreadSchedulingLatency","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"jvm.threads.hiccup.max","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":5000000.0}},"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":3000000.0}},"jfr-diagnostic-tracking":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":5000000.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atAllTimes","atAllTimes":{}}}}},"message":"Service is taking an exceedingly long time to execute scheduled work. This could be the result of\ntoo few CPUs, too many threads, too much load from an operation dominating the available resources, or\nany combination thereof.\nPlease investigate the garbage collection statistics, thread counts, GC statistics, safepoint time, and system load.\nRefer to https://grafana.palantircloud.com/grafana/d/aa30872f-89fc-4ccf-9d21-bdb237e33309/witchcraft-improved for server metrics.","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"ThreadUtilization","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.worker.utilization-max.value","tags":{},"tagExclusions":{},"aggregations":["apolloenvironmentid","host","nodeId"]},"events":{"events":{"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.8}},"jfr-diagnostic-tracking":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.9}}}},"window":"TEN_MINUTES","frequency":{"type":"atAllTimes","atAllTimes":{}}}}},"message":"Service is using more than 90% of its maximum worker threads.","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}},{"id":"ThreadsDeadlock","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"jvm.threads.deadlock.count.value","tags":{},"tagExclusions":{},"aggregations":["deployment","host","nodeId","service","product"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}},"jfr-diagnostic-no-ticket":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}},"p0-business-hours":{"comparator":"GREATER_THAN_EQUAL_TO","value":{"type":"double","double":1.0}}}},"window":"FIVE_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"Detected threads that are potentially deadlocked. Examine the JFR recording or thread dump to identify the\nrelevant threads and locks.","aggregationScheme":null},{"id":"WitchcraftStartupFailed","origin":"com.palantir.witchcraft:witchcraft:4.237.0","specificity":"PRODUCT","parameters":{},"monitor":{"type":"query","query":{"type":"simpleThreshold","simpleThreshold":{"series":{"metric":"server.startup.failed.value","tags":{},"tagExclusions":{"product":[{"type":"string","string":"storage-controller"},{"type":"string","string":"cassandra-operator"}]},"aggregations":["apolloenvironmentid","deployment","host","nodeId","service","product"]},"events":{"events":{"fail-adjudication":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}},"tracking":{"comparator":"GREATER_THAN","value":{"type":"double","double":0.0}}}},"window":"THIRTY_MINUTES","frequency":{"type":"atLeastOnce","atLeastOnce":{}}}}},"message":"The service failed to fully initialize, failing with an exception. Check the service logs for\norigin `com.palantir.witchcraft.Witchcraft` with the message `Failed to start Witchcraft`.","aggregationScheme":{"monitorOrigin":false,"parameters":[],"monitorAggregations":["apolloenvironmentid"],"aggregationWindow":{"amount":7,"unit":"DAYS"},"rateLimitWindow":{"amount":1,"unit":"HOURS"}}}]}